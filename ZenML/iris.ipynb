{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Umgebung Einstellungen **\n"
      ],
      "metadata": {
        "id": "oEXpaXZtYpfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNYNNSXaWebE"
      },
      "outputs": [],
      "source": [
        "%pip install \"zenml[server]\"  # install ZenML\n",
        "!zenml integration install sklearn mlflow evidently -y  # install ZenML integrations\n",
        "!zenml init  # Initialize a ZenML repository\n",
        "%pip install pyparsing==2.4.2  # required for Colab\n",
        "\n",
        "import IPython\n",
        "\n",
        "# automatically restart kernel\n",
        "IPython.Application.instance().kernel.do_shutdown(restart=True)\n",
        "NGROK_TOKEN = \"2PwBKgYHkhfGIKihk3LZ77LAUo4_4yLTDK9r7FtXeDeHz562y\"\n",
        "from zenml.environment import Environment\n",
        "\n",
        "if Environment.in_google_colab():  # Colab only setup\n",
        "    # install ngrok and set auth token\n",
        "    !pip install pyngrok\n",
        "    !ngrok authtoken {NGROK_TOKEN}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stacks zum Projekt hinzufügen**"
      ],
      "metadata": {
        "id": "M3qcU0HvYj94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the MLflow experiment tracker\n",
        "!zenml experiment-tracker register mlflow_tracker --flavor=mlflow\n",
        "\n",
        "# Register the MLflow model registry\n",
        "!zenml model-registry register mlflow_registry --flavor=mlflow\n",
        "\n",
        "# Register the MLflow model deployer\n",
        "!zenml model-deployer register mlflow_deployer --flavor=mlflow\n",
        "\n",
        "# Register the Evidently data validator\n",
        "!zenml data-validator register evidently_validator --flavor=evidently\n",
        "\n",
        "# Register a new stack with the new stack components\n",
        "!zenml stack register my_project_stack -a default\\\n",
        "                                       -o default\\\n",
        "                                       -d mlflow_deployer\\\n",
        "                                       -e mlflow_tracker\\\n",
        "                                       -r mlflow_registry\\\n",
        "                                       -dv evidently_validator\\\n",
        "\n",
        "!zenml stack set my_project_stack\n",
        "\n",
        "# Visualize the current ZenML stack\n",
        "!zenml stack describe"
      ],
      "metadata": {
        "id": "ZVkdyhidWvys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Daten Beschaffung für das Training Pipeline und das Inference Pipeline**"
      ],
      "metadata": {
        "id": "gImP0TBOYOAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from zenml import step\n",
        "from zenml.steps import Output\n",
        "\n",
        "\n",
        "@step\n",
        "def training_data_loader() -> Output(\n",
        "    X_train=pd.DataFrame,\n",
        "    X_test=pd.DataFrame,\n",
        "    y_train=pd.Series,\n",
        "    y_test=pd.Series,\n",
        "):\n",
        "    \"\"\"Load the iris dataset as tuple of Pandas DataFrame / Series.\"\"\"\n",
        "    iris = load_iris(as_frame=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        iris.data, iris.target, test_size=0.2, shuffle=True, random_state=42\n",
        "    )\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "@step\n",
        "def inference_data_loader() -> pd.DataFrame:\n",
        "    \"\"\"Load some (random) inference data.\"\"\"\n",
        "    return pd.DataFrame(\n",
        "        data=np.random.rand(10, 4) * 10,  # assume range [0, 10]\n",
        "        columns=load_iris(as_frame=True).data.columns,\n",
        "    )"
      ],
      "metadata": {
        "id": "wT9uPeYUXQdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modell Trainieren SVC Algorithm**"
      ],
      "metadata": {
        "id": "rwDOpk_sYafp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from zenml.client import Client\n",
        "\n",
        "experiment_tracker = Client().active_stack.experiment_tracker\n",
        "\n",
        "@step(enable_cache=False, experiment_tracker=experiment_tracker.name)\n",
        "def svc_trainer_mlflow(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        ") -> ClassifierMixin:\n",
        "    \"\"\"trainieren  sklearn SVC classifier und log in MLflow.\"\"\"\n",
        "    mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
        "    model = SVC(gamma=0.01)\n",
        "    model.fit(X_train.to_numpy(), y_train.to_numpy())\n",
        "    train_acc = model.score(X_train.to_numpy(), y_train.to_numpy())\n",
        "    print(f\"Train accuracy: {train_acc}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "6eUDzokfXf3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modell Bewertung**"
      ],
      "metadata": {
        "id": "vgrc7PCUZUNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@step\n",
        "def evaluator(\n",
        "    X_test: pd.DataFrame,\n",
        "    y_test: pd.Series,\n",
        "    model: ClassifierMixin,\n",
        ") -> float:\n",
        "    \"\"\"Accuracy auf test set berechnen\"\"\"\n",
        "    test_acc = model.score(X_test.to_numpy(), y_test.to_numpy())\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    return test_acc"
      ],
      "metadata": {
        "id": "bzNICc-CZTUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment Trigger: Das Modell deployen falls die Ergebnisse gut sind also ab 90%"
      ],
      "metadata": {
        "id": "W7TxRCGNZtpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@step\n",
        "def deployment_trigger(test_acc: float) -> bool:\n",
        "    \"\"\"nur deployen wenn accuracy > 90%.\"\"\"\n",
        "    return test_acc > 0.9"
      ],
      "metadata": {
        "id": "R9y4IvT3Zsvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modell Deployment"
      ],
      "metadata": {
        "id": "egsdXj6YbAGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.integrations.mlflow.steps.mlflow_deployer import mlflow_model_registry_deployer_step\n",
        "from zenml.integrations.mlflow.steps.mlflow_registry import mlflow_register_model_step\n",
        "from zenml.model_registries.base_model_registry import ModelRegistryModelMetadata\n",
        "\n",
        "model_deployer = mlflow_model_registry_deployer_step.with_options(\n",
        "    parameters=dict(\n",
        "        registry_model_name=\"my-model\",\n",
        "        registry_model_version=\"1\",\n",
        "        # or you can use the model stage if you have set it in the MLflow registry\n",
        "        # registered_model_stage=\"None\" # \"Staging\", \"Production\", \"Archived\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "srLzaokaZ9q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Drift"
      ],
      "metadata": {
        "id": "cZ14YVBRcfE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.integrations.evidently.steps import (\n",
        "    evidently_profile_step,\n",
        ")\n",
        "\n",
        "drift_detector = evidently_profile_step.with_options(\n",
        "    parameters=dict(profile_sections=[\"datadrift\"])\n",
        ")"
      ],
      "metadata": {
        "id": "riVgBL8Icid2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Loader"
      ],
      "metadata": {
        "id": "lNSGdqu9ctO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.services import BaseService\n",
        "from zenml.client import Client\n",
        "\n",
        "\n",
        "@step(enable_cache=False)\n",
        "def prediction_service_loader() -> BaseService:\n",
        "    \"\"\"Load the model service of our train_evaluate_deploy_pipeline.\"\"\"\n",
        "    client = Client()\n",
        "    model_deployer = client.active_stack.model_deployer\n",
        "    services = model_deployer.find_model_server(\n",
        "        pipeline_name=\"training_pipeline\",\n",
        "        pipeline_step_name=\"model_deployer\",\n",
        "        running=True,\n",
        "    )\n",
        "    service = services[0]\n",
        "    return service"
      ],
      "metadata": {
        "id": "kPQHg1eccrDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictior"
      ],
      "metadata": {
        "id": "VSkVOjOkd4jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@step\n",
        "def predictor(\n",
        "    service: BaseService,\n",
        "    data: pd.DataFrame,\n",
        ") -> Output(predictions=list):\n",
        "    \"\"\"Run a inference request against a prediction service\"\"\"\n",
        "    service.start(timeout=10)  # should be a NOP if already started\n",
        "    prediction = service.predict(data.to_numpy())\n",
        "    prediction = prediction.argmax(axis=-1)\n",
        "    print(f\"Prediction is: {[prediction.tolist()]}\")\n",
        "    return [prediction.tolist()]"
      ],
      "metadata": {
        "id": "gG1lMqfkd0oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline ausführen"
      ],
      "metadata": {
        "id": "a8u3Bn3beAHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml import pipeline\n",
        "\n",
        "@pipeline(enable_cache=False)\n",
        "def training_pipeline():\n",
        "    \"\"\"Train, evaluate, and deploy a model.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = training_data_loader()\n",
        "    model = svc_trainer_mlflow(X_train=X_train, y_train=y_train)\n",
        "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
        "    mlflow_register_model_step.with_options(\n",
        "        parameters=dict(\n",
        "            name=\"my-model\",\n",
        "            metadata=ModelRegistryModelMetadata(gamma=0.01, arch=\"svc\"),\n",
        "            description=\"The first run of the Quickstart pipeline.\",\n",
        "        )\n",
        "    )(model)\n",
        "\n",
        "training_pipeline()"
      ],
      "metadata": {
        "id": "WBz3kswTeD3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log"
      ],
      "metadata": {
        "id": "EaDVyfdDefyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zenml model-registry models list\n",
        "\n",
        "!zenml model-registry models list-versions my-model"
      ],
      "metadata": {
        "id": "N_Vzi9iHebMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Pipeline deployen"
      ],
      "metadata": {
        "id": "T5dHOzUBetwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline()\n",
        "def inference_pipeline():\n",
        "    \"\"\"Inference pipeline with skew and drift detection.\"\"\"\n",
        "    inference_data = inference_data_loader()\n",
        "    model_deployment_service = model_deployer()\n",
        "    predictor(service=model_deployment_service, data=inference_data)\n",
        "    training_data, _, _, _ = training_data_loader()\n",
        "    drift_detector(training_data, inference_data)\n",
        "\n",
        "inference_pipeline()"
      ],
      "metadata": {
        "id": "iv6zgOEJesMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Um alle Modelle im Prod zu sehen"
      ],
      "metadata": {
        "id": "OXLYhYQoe3K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zenml model-deployer models list"
      ],
      "metadata": {
        "id": "Xts7DS-ze_zz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}